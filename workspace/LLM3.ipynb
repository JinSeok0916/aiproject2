{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\aiproject2\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow MobileNetV2 모델 로드\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_url):\n",
    "    try:\n",
    "        # URL에서 이미지 가져오기\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content)).resize((224, 224))  # BytesIO 사용하여 이미지 열기\n",
    "\n",
    "        # 이미지를 배열로 변환\n",
    "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image_array = tf.expand_dims(image_array, axis=0)  # 배치 차원 추가\n",
    "        image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)  # 전처리\n",
    "\n",
    "        # 예측 수행\n",
    "        predictions = model.predict(image_array)\n",
    "        decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]  # 상위 3개 예측 결과 반환\n",
    "\n",
    "        # Gradio Label 컴포넌트에 맞게 결과 형식 변경\n",
    "        # {label1: confidence1, label2: confidence2, ...} 형식으로 반환\n",
    "        result = {label: float(prob) for (_, label, prob) in decoded_predictions}\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1.0}  # 에러 발생 시 기본값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 생성\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n",
    "    outputs=gr.Label(num_top_classes=3, label=\"예측 결과\"),\n",
    "    title=\"음식 이미지 분류\",\n",
    "    description=\"이미지 URL을 입력하면 상위 3개의 예측 결과를 확률과 함께 표시합니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인터페이스 실행\n",
    "iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)\n",
    "\n",
    "# 예시 이미지 URL : https://health.chosun.com/site/data/img_dir/2024/04/19/2024041901914_0.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow MobileNetV2 모델 로드\n",
    "model = tf.keras.applications.MobileNetV2(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_SERVER = \"http://localhost:11434\"  # 로컬 서버 주소\n",
    "MODEL_NAME = \"gemma2\"  # 사용하려는 Ollama 모델 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama를 사용해 음식 설명 생성\n",
    "def get_food_description_with_langchain(food_name):\n",
    "    \"\"\"\n",
    "    LangChain ChatOllama를 사용하여 음식 설명 생성\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat = ChatOllama(base_url=OLLAMA_SERVER, model=MODEL_NAME)\n",
    "        prompt = f\"{food_name}에 대해 말해줘.\"\n",
    "        response = chat.predict(prompt)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Failed to retrieve description: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 예측 함수\n",
    "def predict_image_with_description(image_url):\n",
    "    \"\"\"\n",
    "    이미지 URL을 받아 음식 예측과 Ollama 설명을 반환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # URL에서 이미지 가져오기\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content)).resize((224, 224))  # BytesIO 사용하여 이미지 열기\n",
    "\n",
    "        # 이미지를 배열로 변환\n",
    "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image_array = tf.expand_dims(image_array, axis=0)  # 배치 차원 추가\n",
    "        image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)  # 전처리\n",
    "\n",
    "        # 예측 수행\n",
    "        predictions = model.predict(image_array)\n",
    "        decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]  # 상위 3개 예측 결과 반환\n",
    "\n",
    "        # 예측 결과 형식화\n",
    "        result = {label: float(prob) for (_, label, prob) in decoded_predictions}\n",
    "\n",
    "        # 가장 높은 확률의 예측값으로 Ollama 설명 생성\n",
    "        top_food = decoded_predictions[0][1]  # 가장 확률이 높은 음식 이름\n",
    "        description = get_food_description_with_langchain(top_food)\n",
    "\n",
    "        return result, description  # 예측 결과와 Ollama 설명 반환\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": 1.0}, f\"Error: {e}\"  # 에러 발생 시 기본값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 생성\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image_with_description,\n",
    "    inputs=gr.Textbox(label=\"이미지 URL 입력\"),\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=3, label=\"예측 결과\"),  # 상위 3개 예측 결과\n",
    "        gr.Textbox(label=\"음식 설명\", interactive=False)  # Ollama로 생성한 설명 출력\n",
    "    ],\n",
    "    title=\"음식 이미지 분류 및 설명 생성기\",\n",
    "    description=\"이미지 URL을 입력하면 음식 분류 결과와 설명을 제공합니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인터페이스 실행\n",
    "iface.launch(server_port=7861, server_name=\"0.0.0.0\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드 클라우드 생성함수수\n",
    "def generate_wordcloud(file_obj):\n",
    "    try:\n",
    "        # 파일이 없는 경우 처리\n",
    "        if file_obj is None:\n",
    "            return None\n",
    "\n",
    "        # Gradio의 파일 객체에서 파일 경로 가져오기\n",
    "        file_path = file_obj.name\n",
    "\n",
    "        # 파일 읽기\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # 워드클라우드 생성\n",
    "        wordcloud = WordCloud(\n",
    "            font_path='malgun',  # 한글 폰트 설정 (맑은 고딕)\n",
    "            background_color='white',\n",
    "            width=800,\n",
    "            height=600,\n",
    "            max_words=200,\n",
    "            max_font_size=100,\n",
    "            min_font_size=10,\n",
    "            random_state=42\n",
    "        ).generate(text)\n",
    "\n",
    "        # matplotlib 그래프 초기화\n",
    "        plt.clf()\n",
    "\n",
    "        # 워드클라우드 이미지를 플롯\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 결과 이미지를 저장\n",
    "        output_path = 'wordcloud.png'\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()  # 메모리 누수 방지를 위해 figure 닫기\n",
    "        return output_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 생성\n",
    "iface = gr.Interface(\n",
    "    fn=generate_wordcloud,\n",
    "    inputs=gr.File(label=\"Upload a .txt file\"),\n",
    "    outputs=gr.Image(type=\"filepath\", label=\"Word Cloud\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "* Running on public URL: https://4bceebed91eae26d5e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4bceebed91eae26d5e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface.launch(server_port=7861, share=True, server_name=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
